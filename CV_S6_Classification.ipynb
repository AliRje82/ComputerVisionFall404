{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MNIST Classification with Classic Features\n",
        "\n",
        "This notebook demonstrates how to classify the MNIST handwritten digits using classical computer vision features. We extract:\n",
        "\n",
        "* **Object analysis features** (e.g., area, aspect ratio, eccentricity, solidity, Hu moments) from binarized digits.\n",
        "* **Texture features** via Local Binary Patterns (LBP).\n",
        "\n",
        "The combined descriptors feed into a one-vs-all Support Vector Machine (SVM) classifier.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, ConfusionMatrixDisplay\n",
        "from skimage.feature import local_binary_pattern\n",
        "from skimage.measure import label, regionprops, moments_hu\n",
        "\n",
        "np.random.seed(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the MNIST dataset\n",
        "\n",
        "We load the images and labels from `fetch_openml` and optionally down-sample for quicker experimentation. Images are kept as 28\u00d728 grayscale arrays for feature extraction.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
        "images = mnist.data.reshape(-1, 28, 28).astype(np.float32) / 255.0\n",
        "labels = mnist.target.astype(int)\n",
        "\n",
        "n_samples = 20000  # adjust down if running on limited hardware\n",
        "indices = np.random.choice(len(images), size=n_samples, replace=False)\n",
        "images = images[indices]\n",
        "labels = labels[indices]\n",
        "\n",
        "print(f\"Dataset subset: {images.shape[0]} samples\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature extraction helpers\n",
        "\n",
        "* **Object analysis**: binarize the digit, find connected components, and compute shape attributes.\n",
        "* **Texture**: compute uniform LBP and summarize it with a normalized histogram.\n",
        "* **Combined descriptor**: concatenate object and texture vectors for each image.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_object_features(image: np.ndarray) -> np.ndarray:\n",
        "    binary = image > 0.2\n",
        "    labeled = label(binary)\n",
        "    props = regionprops(labeled)\n",
        "    if not props:\n",
        "        return np.zeros(12, dtype=np.float32)\n",
        "    region = max(props, key=lambda p: p.area)\n",
        "    area = region.area / (image.shape[0] * image.shape[1])\n",
        "    eccentricity = region.eccentricity\n",
        "    extent = region.extent\n",
        "    solidity = region.solidity\n",
        "    minr, minc, maxr, maxc = region.bbox\n",
        "    height, width = maxr - minr, maxc - minc\n",
        "    aspect_ratio = width / height if height > 0 else 0.0\n",
        "    hu = moments_hu(binary.astype(np.float64))\n",
        "    hu = np.sign(hu) * np.log1p(np.abs(hu))\n",
        "    return np.hstack([\n",
        "        area,\n",
        "        aspect_ratio,\n",
        "        eccentricity,\n",
        "        extent,\n",
        "        solidity,\n",
        "        hu,\n",
        "    ]).astype(np.float32)\n",
        "\n",
        "\n",
        "def extract_texture_features(image: np.ndarray, radius: int = 2, n_points: int | None = None) -> np.ndarray:\n",
        "    if n_points is None:\n",
        "        n_points = 8 * radius\n",
        "    lbp = local_binary_pattern(image, n_points, radius, method=\"uniform\")\n",
        "    hist, _ = np.histogram(lbp, bins=np.arange(0, n_points + 3), range=(0, n_points + 2), density=True)\n",
        "    return hist.astype(np.float32)\n",
        "\n",
        "\n",
        "def extract_features(image: np.ndarray) -> np.ndarray:\n",
        "    obj_feats = extract_object_features(image)\n",
        "    tex_feats = extract_texture_features(image)\n",
        "    return np.hstack([obj_feats, tex_feats])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build the feature matrix\n",
        "\n",
        "Compute the descriptors for every image. We keep a few examples to visualize the binary masks and LBP responses for intuition.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feature_list = [extract_features(img) for img in images]\n",
        "X = np.vstack(feature_list)\n",
        "y = labels\n",
        "\n",
        "print(f\"Feature matrix shape: {X.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
        "for ax, idx in zip(axes.flat, range(5)):\n",
        "    img = images[idx]\n",
        "    binary = img > 0.2\n",
        "    lbp = local_binary_pattern(img, 16, 2, method=\"uniform\")\n",
        "    ax.imshow(np.hstack([img, binary, lbp / lbp.max()]), cmap='gray')\n",
        "    ax.set_title(f\"Label: {labels[idx]}\")\n",
        "    ax.axis('off')\n",
        "plt.suptitle(\"Example digits with binary mask and LBP\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train a one-vs-all SVM classifier\n",
        "\n",
        "We standardize the feature matrix and fit a linear SVM. `LinearSVC` uses the one-vs-all strategy by default, which suits the multi-class MNIST problem.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "svm_clf = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    LinearSVC(dual=False, random_state=42)\n",
        ")\n",
        "svm_clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = svm_clf.predict(X_test)\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(f\"Test accuracy: {acc:.4f}\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize the confusion matrix\n",
        "\n",
        "The confusion matrix highlights which digits remain challenging for the classical feature set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, y_pred, cmap='Blues', normalize='true', ax=ax)\n",
        "ax.set_title(\"Linear SVM (one-vs-all) on Object + Texture Features\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}